import os

import yaml


def save_yaml(name, data):
    path = f"output/debug/{name}.yml"
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        yaml.dump(data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)
    print(f"Generated: {path}")


# å…¬å…±å¤´éƒ¨
BASE_APP = {
    "kind": "app",
    "version": "0.1.5",  # å°è¯•é™ä½ç‰ˆæœ¬å·ä»¥æé«˜å…¼å®¹æ€§ï¼Œæˆ–è€…ä½¿ç”¨ä½ æä¾›çš„ sample çš„ç‰ˆæœ¬
    "app": {"name": "Debug_Workflow", "mode": "workflow", "icon": "ğŸ", "icon_background": "#FFEAD5"},
}


# Level 1: Start -> End
def gen_level_1():
    data = BASE_APP.copy()
    data["app"]["name"] = "Debug_L1_Start_End"
    data["workflow"] = {
        "graph": {
            "nodes": [
                {
                    "id": "start",
                    "type": "custom",
                    "data": {
                        "type": "start",
                        "title": "å¼€å§‹",
                        "variables": [{"variable": "input_text", "label": "è¾“å…¥", "type": "string"}],
                    },
                    "position": {"x": 0, "y": 0},
                },
                {
                    "id": "end",
                    "type": "custom",
                    "data": {
                        "type": "end",
                        "title": "ç»“æŸ",
                        "outputs": [{"variable": "result", "value_selector": ["start", "input_text"]}],
                    },
                    "position": {"x": 300, "y": 0},
                },
            ],
            "edges": [
                {
                    "id": "e1",
                    "source": "start",
                    "sourceHandle": "source",
                    "target": "end",
                    "targetHandle": "target",
                    "type": "custom",
                }
            ],
        }
    }
    save_yaml("level_1_base", data)


# Level 2: Start -> LLM -> End
def gen_level_2():
    data = BASE_APP.copy()
    data["app"]["name"] = "Debug_L2_LLM"
    data["workflow"] = {
        "graph": {
            "nodes": [
                {
                    "id": "start",
                    "type": "custom",
                    "data": {
                        "type": "start",
                        "title": "å¼€å§‹",
                        "variables": [{"variable": "input_text", "label": "è¾“å…¥", "type": "string"}],
                    },
                    "position": {"x": 0, "y": 0},
                },
                {
                    "id": "llm_node",
                    "type": "custom",
                    "data": {
                        "type": "llm",
                        "title": "LLMç”Ÿæˆ",
                        "model": {"provider": "openai", "name": "gpt-4o", "mode": "chat"},
                        "prompt_template": [
                            {"role": "system", "text": "ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚"},
                            {"role": "user", "text": "{{#start.input_text#}}"},
                        ],
                        # å…³é”®ï¼šæ£€æŸ¥è¿™äº›é»˜è®¤å­—æ®µæ˜¯å¦å¯¼è‡´å´©æºƒ
                        "memory": {"window": {"enabled": False, "size": 10}, "query_prompt_template": ""},
                        "context": {"enabled": False, "variable_selector": []},
                        "vision": {"enabled": False},
                    },
                    "position": {"x": 300, "y": 0},
                },
                {
                    "id": "end",
                    "type": "custom",
                    "data": {
                        "type": "end",
                        "title": "ç»“æŸ",
                        "outputs": [{"variable": "result", "value_selector": ["llm_node", "text"]}],
                    },
                    "position": {"x": 600, "y": 0},
                },
            ],
            "edges": [
                {
                    "id": "e1",
                    "source": "start",
                    "sourceHandle": "source",
                    "target": "llm_node",
                    "targetHandle": "target",
                    "type": "custom",
                },
                {
                    "id": "e2",
                    "source": "llm_node",
                    "sourceHandle": "source",
                    "target": "end",
                    "targetHandle": "target",
                    "type": "custom",
                },
            ],
        }
    }
    save_yaml("level_2_llm", data)


# Level 3: Start -> If-Else -> End
# è¿™æ˜¯æœ€å®¹æ˜“å´©çš„åœ°æ–¹
def gen_level_3():
    data = BASE_APP.copy()
    data["app"]["name"] = "Debug_L3_IfElse"
    data["workflow"] = {
        "graph": {
            "nodes": [
                {
                    "id": "start",
                    "type": "custom",
                    "data": {
                        "type": "start",
                        "title": "å¼€å§‹",
                        "variables": [{"variable": "input_text", "label": "è¾“å…¥", "type": "string"}],
                    },
                    "position": {"x": 0, "y": 0},
                },
                {
                    "id": "router",
                    "type": "custom",
                    "data": {
                        "type": "if-else",
                        "title": "è·¯ç”±",
                        "conditions": [
                            {
                                "id": "true",  # Dify æ ‡å‡† if-else åªæœ‰ true/false
                                "operator": "contains",
                                "variable_selector": ["start", "input_text"],
                                "value": "a",
                            }
                        ],
                        "logical_operator": "and",
                    },
                    "position": {"x": 300, "y": 0},
                },
                {
                    "id": "end_true",
                    "type": "custom",
                    "data": {
                        "type": "end",
                        "title": "ç»“æŸA",
                        "outputs": [{"variable": "res", "value_selector": ["start", "input_text"]}],
                    },
                    "position": {"x": 600, "y": -100},
                },
                {
                    "id": "end_false",
                    "type": "custom",
                    "data": {
                        "type": "end",
                        "title": "ç»“æŸB",
                        "outputs": [{"variable": "res", "value_selector": ["start", "input_text"]}],
                    },
                    "position": {"x": 600, "y": 100},
                },
            ],
            "edges": [
                {
                    "id": "e1",
                    "source": "start",
                    "sourceHandle": "source",
                    "target": "router",
                    "targetHandle": "target",
                    "type": "custom",
                },
                # å…³é”®ï¼šæ£€æŸ¥ sourceHandle æ˜¯å¦å¯¹åº” conditions çš„ id
                {
                    "id": "e2",
                    "source": "router",
                    "sourceHandle": "true",
                    "target": "end_true",
                    "targetHandle": "target",
                    "type": "custom",
                },
                {
                    "id": "e3",
                    "source": "router",
                    "sourceHandle": "false",
                    "target": "end_false",
                    "targetHandle": "target",
                    "type": "custom",
                },
            ],
        }
    }
    save_yaml("level_3_ifelse", data)


if __name__ == "__main__":
    gen_level_1()
    gen_level_2()
    gen_level_3()
